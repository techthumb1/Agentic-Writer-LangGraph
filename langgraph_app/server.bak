"""
Gold-Standard Agentic Writer API Server
Integrates with LangGraph enhanced content generation system
"""

import asyncio
import os
import uuid
import yaml
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse, Response
from fastapi.exception_handlers import HTTPException as FastAPIHTTPException
from pydantic import BaseModel, Field, field_validator
import uvicorn
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST, CollectorRegistry, REGISTRY
import structlog
import traceback

# Import your enhanced graph system
LANGGRAPH_AVAILABLE = False
try:
    from langgraph_app.enhanced_graph import (
        EnhancedContentGraph, 
        AgentState, 
        ProcessingStatus,
        MetricsCollector
    )
    from .enhanced_model_registry import get_model
    LANGGRAPH_AVAILABLE = True
    print("‚úÖ LangGraph modules loaded successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è LangGraph modules not available: {e}")
    print("üîÑ Using mock implementations for testing")
    
    class MockProcessingStatus:
        COMPLETED = "completed"
        FAILED = "failed"
        PENDING = "pending"
        PROCESSING = "processing"
    
    ProcessingStatus = MockProcessingStatus()
    
    class MockAgentState:
        def __init__(self, **kwargs):
            self.requestId = kwargs.get('requestId', '')
            self.status = kwargs.get('status', ProcessingStatus.PENDING)
            self.progress = kwargs.get('progress', 0.0)
            self.content = kwargs.get('content', '')
            self.metadata = kwargs.get('metadata', {})
            self.errors = kwargs.get('errors', [])
            self.warnings = kwargs.get('warnings', [])
            self.metrics = kwargs.get('metrics', {})
            self.started_at = kwargs.get('started_at', datetime.now())
            self.completed_at = kwargs.get('completed_at', None)
    
    AgentState = MockAgentState
    
    class MockMetricsCollector:
        def __init__(self):
            self.metrics = {}
        
        def start_timer(self, name):
            pass
        
        def end_timer(self, name):
            return 1.0
        
        def get_metrics(self):
            return self.metrics
    
    MetricsCollector = MockMetricsCollector
    
    class MockContentGraph:
        def __init__(self, llm):
            self.llm = llm
            print("üé≠ Mock content graph initialized")
        
        async def generate_content(self, requestId, template_config, style_config):
            print(f"üé≠ Mock generating content for request: {requestId}")
            
            # Simulate realistic generation process
            import asyncio
            
            # Simulate multiple steps with progress updates
            steps = [
                (0.2, "Researching topic..."),
                (0.4, "Planning structure..."),
                (0.6, "Writing content..."),
                (0.8, "Editing and refining..."),
                (1.0, "Finalizing...")
            ]
            
            for progress, step in steps:
                await asyncio.sleep(0.5)  # Simulate work
                print(f"üé≠ Progress: {int(progress*100)}% - {step}")
            
            # Generate mock content based on template
            topic = template_config.get('dynamic_parameters', {}).get('topic', 'Sample Topic')
            template_name = template_config.get('name', 'Unknown Template')
            style_name = style_config.get('name', 'Unknown Style')
            
            mock_content = f"""# {topic}

This is a professionally generated article about {topic}.

## Introduction

This content was created using the **{template_name}** template with **{style_name}** styling. The content demonstrates the capabilities of our agentic writing system.

## Key Points

- **Advanced AI Generation**: Utilizes sophisticated language models for content creation
- **Template-Based Structure**: Follows predefined templates for consistency
- **Style Customization**: Applies specific writing styles and tones
- **Quality Assurance**: Includes editing and refinement processes

## Detailed Content

{topic} represents an important area of study and application. Through careful analysis and structured presentation, we can explore its various dimensions and implications.

The methodical approach ensures that all aspects are covered comprehensively while maintaining readability and engagement.

## Technical Implementation

Our system leverages:
- LangGraph for orchestrating AI agents
- FastAPI for robust backend services  
- React for dynamic frontend interfaces
- Real-time progress tracking and monitoring

## Conclusion

This demonstrates the power of combining advanced AI with well-structured templates and styles to produce high-quality content efficiently.

---

*Generated on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} using Agentic Writer v2.0*
*Template: {template_name} | Style: {style_name} | Request ID: {requestId}*
"""
            
            mock_result = MockAgentState(
                requestId=requestId,
                status=ProcessingStatus.COMPLETED,
                progress=1.0,
                content=mock_content,
                metadata={
                    "template": template_name,
                    "style_profile": style_name,
                    "generated_at": datetime.now().isoformat(),
                    "word_count": len(mock_content.split()),
                    "character_count": len(mock_content),
                    "mock_generation": True
                },
                errors=[],
                warnings=["This is mock content for testing"],
                metrics={
                    "word_count": len(mock_content.split()),
                    "generation_time": 2.5,
                    "template_used": template_name,
                    "style_used": style_name
                },
                started_at=datetime.now(),
                completed_at=datetime.now()
            )
            
            print(f"‚úÖ Mock content generated: {len(mock_content)} characters")
            return mock_result
    
    EnhancedContentGraph = MockContentGraph
    
    def get_model(model_name):
        print(f"üé≠ Mock model requested: {model_name}")
        return None  # Mock model

# Configure structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Create a custom registry for this application to avoid conflicts
custom_registry = CollectorRegistry()

# Prometheus metrics with error handling for duplicates
def get_or_create_counter(name, description, labels, registry=None):
    """Get existing counter or create new one, avoiding duplicates"""
    if registry is None:
        registry = custom_registry
    
    try:
        # Try to create the counter
        return Counter(name, description, labels, registry=registry)
    except ValueError as e:
        if "Duplicated timeseries" in str(e):
            # If it already exists, find and return it
            for collector in registry._collector_to_names:
                if hasattr(collector, '_name') and collector._name == name:
                    return collector
            # If we can't find it, create with a slightly different name
            return Counter(f"{name}_new", description, labels, registry=registry)
        raise

def get_or_create_histogram(name, description, registry=None):
    """Get existing histogram or create new one, avoiding duplicates"""
    if registry is None:
        registry = custom_registry
    
    try:
        return Histogram(name, description, registry=registry)
    except ValueError as e:
        if "Duplicated timeseries" in str(e):
            # If it already exists, find and return it
            for collector in registry._collector_to_names:
                if hasattr(collector, '_name') and collector._name == name:
                    return collector
            # If we can't find it, create with a slightly different name
            return Histogram(f"{name}_new", description, registry=registry)
        raise

# Initialize Prometheus metrics safely
REQUEST_COUNT = get_or_create_counter(
    'agentic_writer_requests_total', 
    'Total requests', 
    ['method', 'endpoint', 'status']
)
REQUEST_DURATION = get_or_create_histogram(
    'agentic_writer_request_duration_seconds', 
    'Request duration'
)
GENERATION_COUNT = get_or_create_counter(
    'content_generation_total', 
    'Total content generations', 
    ['status', 'template']
)
GENERATION_DURATION = get_or_create_histogram(
    'content_generation_duration_seconds', 
    'Content generation duration'
)

# Custom JSON encoder for datetime serialization
from datetime import datetime
import json

class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

# Pydantic models with comprehensive validation
class TemplateParameter(BaseModel):
    name: str = Field(..., min_length=1, max_length=100)
    label: str = Field(..., min_length=1, max_length=200)
    type: str = Field(..., pattern=r'^(string|text|textarea|number|select|boolean|array|date|email|url)$')
    description: Optional[str] = Field(None, max_length=500)
    placeholder: Optional[str] = Field(None, max_length=500)
    default: Optional[Union[str, int, float, bool, List[str]]] = None
    options: Optional[List[str]] = Field(None, max_items=100)
    required: bool = Field(default=False)
    validation: Optional[Dict[str, Any]] = Field(default_factory=dict)

class ContentTemplate(BaseModel):
    id: str = Field(..., min_length=1, max_length=100)
    slug: str = Field(..., min_length=1, max_length=100)
    name: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = Field(None, max_length=1000)
    category: Optional[str] = Field(None, max_length=100)
    
    # Enhanced fields for unified structure
    defaults: Dict[str, Any] = Field(default_factory=dict)
    system_prompt: Optional[str] = Field(None, max_length=5000)
    structure: Optional[Dict[str, Any]] = Field(default_factory=dict)
    research: Optional[Dict[str, Any]] = Field(default_factory=dict)
    
    parameters: Dict[str, TemplateParameter] = Field(default_factory=dict)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    version: str = Field(default="1.0.0")
    filename: str

class StyleProfile(BaseModel):
    id: str = Field(..., min_length=1, max_length=100)
    name: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = Field(None, max_length=1000)
    category: str = Field(default="general", max_length=100)
    platform: Optional[str] = Field(None, max_length=100)
    tone: Optional[str] = Field(None, max_length=100)
    voice: Optional[str] = Field(None, max_length=100)
    structure: Optional[str] = Field(None, max_length=500)
    audience: Optional[str] = Field(None, max_length=200)
    
    # Enhanced fields for unified structure
    system_prompt: Optional[str] = Field(None, max_length=5000)
    length_limit: Optional[Dict[str, Any]] = Field(default_factory=dict)
    settings: Dict[str, Any] = Field(default_factory=dict)
    formatting: Dict[str, Any] = Field(default_factory=dict)
    
    metadata: Dict[str, Any] = Field(default_factory=dict)
    filename: str

def parse_template_parameters(parameters_data: Any) -> Dict[str, TemplateParameter]:
    """Parse parameters from various formats (dict, list, or mixed) - FIXED VERSION"""
    processed_parameters = {}
    
    if isinstance(parameters_data, dict):
        # Handle dict format: {param_name: {config...}}
        for key, param in parameters_data.items():
            if isinstance(param, dict):
                # Full parameter specification
                processed_parameters[key] = TemplateParameter(
                    name=key,
                    label=param.get('label', key.replace('_', ' ').title()),
                    type=param.get('type', 'string'),
                    description=param.get('description'),
                    placeholder=param.get('placeholder'),
                    default=param.get('default'),
                    options=param.get('options'),
                    required=param.get('required', False)
                )
            else:
                # Simple parameter (just name and value)
                processed_parameters[key] = TemplateParameter(
                    name=key,
                    label=key.replace('_', ' ').title(),
                    type='string',
                    default=param if param is not None else None,
                    required=False
                )
    
    elif isinstance(parameters_data, list):
        # Handle list format: [{name: ..., type: ...}, ...] or [param_name1, param_name2, ...]
        for param in parameters_data:
            if isinstance(param, dict) and 'name' in param:
                # Full parameter dict with name field
                param_name = param['name']
                processed_parameters[param_name] = TemplateParameter(
                    name=param_name,
                    label=param.get('label', param_name.replace('_', ' ').title()),
                    type=param.get('type', 'string'),
                    description=param.get('description'),
                    placeholder=param.get('placeholder'),
                    default=param.get('default'),
                    options=param.get('options'),
                    required=param.get('required', False)
                )
            elif isinstance(param, str):
                # Simple string parameter
                processed_parameters[param] = TemplateParameter(
                    name=param,
                    label=param.replace('_', ' ').title(),
                    type='string',
                    required=False
                )
            elif isinstance(param, dict):
                # Dict without explicit 'name' field - use first key as name
                for key, value in param.items():
                    processed_parameters[key] = TemplateParameter(
                        name=key,
                        label=key.replace('_', ' ').title(),
                        type='string',
                        default=value if not isinstance(value, dict) else None,
                        required=False
                    )
                    break  # Only process first key-value pair
    
    else:
        # Handle other types or empty
        logger.warning(f"Unexpected parameters format: {type(parameters_data)}")
    
    return processed_parameters

def load_templates() -> List[ContentTemplate]:
    """Load and validate all content templates with dynamic structure handling - FIXED VERSION"""
    templates = []
    
    for template_dir in get_template_paths():
        logger.info(f"üìÅ Checking template directory: {template_dir}")
        
        if not os.path.exists(template_dir):
            logger.warning(f"Template directory does not exist: {template_dir}")
            continue
            
        try:
            files = os.listdir(template_dir)
            logger.info(f"Files found in {template_dir}: {files}")
            
            for filename in files:
                if not filename.endswith('.yaml'):
                    logger.debug(f"Skipping non-YAML file: {filename}")
                    continue
                
                file_path = os.path.join(template_dir, filename)
                logger.info(f"üìÑ Loading template: {file_path}")
                template_data = load_yaml_file_safe(file_path)
                
                if not template_data:
                    logger.warning(f"Empty or invalid YAML in: {file_path}")
                    continue
                
                try:
                    # Get the template ID from filename or data
                    template_id = template_data.get('id', filename.replace('.yaml', ''))
                    
                    # Parse parameters dynamically - FIXED TO HANDLE LISTS
                    parameters_data = template_data.get("parameters", {})
                    logger.info(f"Processing parameters for {filename}: type={type(parameters_data)}, value={parameters_data}")
                    
                    processed_parameters = parse_template_parameters(parameters_data)
                    
                    # Create template with enhanced structure
                    template = ContentTemplate(
                        id=template_id,
                        slug=template_data.get('slug', template_id),
                        name=template_data.get("name", template_id.replace('_', ' ').title()),
                        description=template_data.get("description", ""),
                        category=template_data.get("category", "general"),
                        
                        # Enhanced fields
                        defaults=template_data.get("defaults", {}),
                        system_prompt=template_data.get("system_prompt"),
                        structure=template_data.get("structure", {}),
                        research=template_data.get("research", {}),
                        
                        parameters=processed_parameters,
                        metadata=template_data.get("metadata", {}),
                        version=template_data.get("version", "1.0.0"),
                        filename=filename
                    )
                    templates.append(template)
                    logger.info(f"‚úÖ Successfully loaded template: {template.name} (ID: {template.id}) with {len(processed_parameters)} parameters")
                    
                except Exception as e:
                    logger.error("Invalid template format", 
                                filename=filename, 
                                error=str(e),
                                template_data_keys=list(template_data.keys()) if isinstance(template_data, dict) else "Not a dict")
                    continue
        
        except Exception as e:
            logger.error("Error loading templates from directory", 
                        directory=template_dir, 
                        error=str(e))
            continue
    
    logger.info(f"üìä Total templates loaded: {len(templates)}")
    for template in templates:
        logger.info(f"  - {template.id}: {template.name}")
    
    return templates

def load_style_profiles() -> List[StyleProfile]:
    """Load and validate all style profiles with enhanced structure"""
    profiles = []
    
    for profile_dir in get_style_profile_paths():
        logger.info(f"üìÅ Checking style profile directory: {profile_dir}")
        
        if not os.path.exists(profile_dir):
            logger.warning(f"Style profile directory does not exist: {profile_dir}")
            continue
            
        try:
            files = os.listdir(profile_dir)
            logger.info(f"Files found in {profile_dir}: {files}")
            
            for filename in files:
                if not filename.endswith('.yaml'):
                    logger.debug(f"Skipping non-YAML file: {filename}")
                    continue
                
                file_path = os.path.join(profile_dir, filename)
                logger.info(f"üìÑ Loading style profile: {file_path}")
                profile_data = load_yaml_file_safe(file_path)
                
                if not profile_data:
                    logger.warning(f"Empty or invalid YAML in: {file_path}")
                    continue
                
                try:
                    # Get the profile ID from filename or data
                    profile_id = profile_data.get('id', filename.replace('.yaml', ''))
                    
                    profile = StyleProfile(
                        id=profile_id,
                        name=profile_data.get("name", profile_id.replace('_', ' ').title()),
                        description=profile_data.get("description", ""),
                        category=profile_data.get("category", "general"),
                        platform=profile_data.get("platform"),
                        tone=profile_data.get("tone"),
                        voice=profile_data.get("voice"),
                        structure=profile_data.get("structure"),
                        audience=profile_data.get("audience"),
                        
                        # Enhanced fields
                        system_prompt=profile_data.get("system_prompt"),
                        length_limit=profile_data.get("length_limit", {}),
                        settings=profile_data.get("settings", {}),
                        formatting=profile_data.get("formatting", {}),
                        
                        metadata=profile_data.get("metadata", {}),
                        filename=filename
                    )
                    profiles.append(profile)
                    logger.info(f"‚úÖ Successfully loaded style profile: {profile.name} (ID: {profile.id})")
                    
                except Exception as e:
                    logger.error("Invalid style profile format", 
                                filename=filename, 
                                error=str(e),
                                profile_data_type=type(profile_data).__name__)
                    continue
        
        except Exception as e:
            logger.error("Error loading style profiles from directory", 
                        directory=profile_dir, 
                        error=str(e))
            continue
    
    logger.info(f"üìä Total style profiles loaded: {len(profiles)}")
    return profiles

# Application lifecycle
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle management"""
    logger.info("üöÄ Starting Agentic Writer API")
    
    # Initialize content graph
    try:
        llm = get_model("writer")
        app.state.content_graph = EnhancedContentGraph(llm)
        app.state.generation_tasks = {}
        app.state.metrics_collector = MetricsCollector()
        logger.info("‚úÖ Content graph initialized successfully")
    except Exception as e:
        logger.error("‚ùå Failed to initialize content graph", error=str(e))
        raise
    
    # Validate configuration paths
    template_paths = get_template_paths()
    style_paths = get_style_profile_paths()
    
    logger.info("üìÅ Configuration paths", 
                template_paths=template_paths,
                style_paths=style_paths)
    
    yield
    
    # Cleanup
    logger.info("üõë Shutting down Agentic Writer API")

# FastAPI application with advanced configuration
app = FastAPI(
    title="Agentic Writer API",
    description="Gold-standard AI-powered content generation using LangGraph",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan
)

# Advanced middleware stack
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://frontend:3000", "https://*.vercel.app"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["X-Request-ID", "X-Generation-Time"]
)

# Request tracking middleware
@app.middleware("http")
async def track_requests(request: Request, call_next):
    requestId = str(uuid.uuid4())
    request.state.requestId = requestId
    
    start_time = datetime.now()
    
    with REQUEST_DURATION.time():
        response = await call_next(request)
    
    duration = (datetime.now() - start_time).total_seconds()
    
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path,
        status=response.status_code
    ).inc()
    
    response.headers["X-Request-ID"] = requestId
    response.headers["X-Response-Time"] = f"{duration:.3f}s"
    
    logger.info("Request completed",
                requestId=requestId,
                method=request.method,
                path=request.url.path,
                status_code=response.status_code,
                duration=duration)
    
    return response

# API Response classes
class GenerateRequest(BaseModel):
    requestId: str = Field(..., min_length=1) 
    template: str = Field(..., min_length=1, max_length=100)
    style_profile: str = Field(..., min_length=1, max_length=100)
    dynamic_parameters: Dict[str, Any] = Field(default_factory=dict, max_items=50)
    priority: int = Field(default=1, ge=1, le=5)
    timeout_seconds: int = Field(default=300, ge=60, le=1800)
    
    @field_validator('dynamic_parameters')
    @classmethod
    def validate_parameters(cls, v):
        # Validate parameter values
        for key, value in v.items():
            if isinstance(value, str) and len(value) > 10000:
                raise ValueError(f"Parameter '{key}' exceeds maximum length")
        return v

class GenerationStatus(BaseModel):
    requestId: str
    status: str = Field(..., pattern=r'^(pending|processing|completed|failed|cancelled)$')
    progress: float = Field(..., ge=0.0, le=1.0)
    current_step: str = Field(default="")
    content: str = Field(default="")
    metadata: Dict[str, Any] = Field(default_factory=dict)
    errors: List[str] = Field(default_factory=list)
    warnings: List[str] = Field(default_factory=list)
    metrics: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime
    updated_at: datetime
    completed_at: Optional[datetime] = None

class PaginationMetadata(BaseModel):
    page: int = Field(..., ge=1)
    limit: int = Field(..., ge=1, le=100)
    total: int = Field(..., ge=0)
    totalPages: int = Field(..., ge=0)
    hasNext: bool
    hasPrev: bool

class APIResponse(BaseModel):
    success: bool
    data: Optional[Any] = None
    error: Optional[Dict[str, Any]] = None
    timestamp: datetime = Field(default_factory=datetime.now)
    requestId: Optional[str] = None

# Advanced exception handling
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    logger.error("HTTP exception",
                 requestId=getattr(request.state, 'requestId', None),
                 status_code=exc.status_code,
                 detail=exc.detail)
    
    response_data = APIResponse(
        success=False,
        error={
            "code": f"HTTP_{exc.status_code}",
            "message": exc.detail,
            "timestamp": datetime.now().isoformat()
        },
        requestId=getattr(request.state, 'requestId', None)
    ).dict()
    
    # Convert datetime objects to strings
    response_data["timestamp"] = response_data["timestamp"].isoformat() if isinstance(response_data["timestamp"], datetime) else response_data["timestamp"]
    
    return JSONResponse(
        status_code=exc.status_code,
        content=response_data
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error("Unhandled exception",
                 requestId=getattr(request.state, 'requestId', None),
                 error=str(exc),
                 exc_info=True)
    
    response_data = APIResponse(
        success=False,
        error={
            "code": "INTERNAL_SERVER_ERROR",
            "message": "An unexpected error occurred",
            "timestamp": datetime.now().isoformat()
        },
        requestId=getattr(request.state, 'requestId', None)
    ).dict()
    
    # Convert datetime objects to strings
    response_data["timestamp"] = response_data["timestamp"].isoformat() if isinstance(response_data["timestamp"], datetime) else response_data["timestamp"]
    
    return JSONResponse(
        status_code=500,
        content=response_data
    )

# Advanced file loading with caching and validation
def get_template_paths() -> List[str]:
    """Get ordered list of template directory paths"""
    paths = [
        "data/content_templates",          # Relative to current directory
        "../data/content_templates",       # One level up (if running from langgraph_app)
        "frontend/content-templates",      # Frontend directory
        "../frontend/content-templates",   # Frontend one level up
        "content-templates"                # Generic fallback
    ]
    existing_paths = [path for path in paths if os.path.exists(path)]
    logger.info(f"üìÇ Template paths checked: {paths}")
    logger.info(f"üìÇ Template paths found: {existing_paths}")
    return existing_paths

def get_style_profile_paths() -> List[str]:
    """Get ordered list of style profile directory paths"""
    paths = [
        "data/style_profiles",            # Relative to current directory  
        "../data/style_profiles",         # One level up (if running from langgraph_app)
        "frontend/style-profiles",        # Frontend directory
        "../frontend/style-profiles",     # Frontend one level up
        "style_profiles",                 # Generic fallback
        "style-profiles"                  # Alternative naming
    ]
    existing_paths = [path for path in paths if os.path.exists(path)]
    logger.info(f"üìÇ Style profile paths checked: {paths}")
    logger.info(f"üìÇ Style profile paths found: {existing_paths}")
    return existing_paths

def load_yaml_file_safe(file_path: str) -> Dict[str, Any]:
    """Load YAML file with comprehensive error handling"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = yaml.safe_load(f)
            if content is None:
    final_state = None  # inserted for safety
                if final_state:
                    return {**final_state, }
                else:
                    return {"error": "final_state undefined", "status": "failed"}
            if not isinstance(content, dict):
                logger.warning("Invalid YAML structure", file_path=file_path)
                return {**final_state, }
            return content
    except yaml.YAMLError as e:
        logger.error("YAML parsing error", file_path=file_path, error=str(e))
        return {**final_state, }
    except FileNotFoundError:
        logger.error("File not found", file_path=file_path)
        return {**final_state, }
    except Exception as e:
        logger.error("Unexpected error loading YAML", file_path=file_path, error=str(e))
        return {**final_state, }

# Background task for content generation
async def generate_content_task(
    requestId: str,
    template_config: Dict[str, Any],
    style_config: Dict[str, Any],
    app_state
):
    """Execute content generation with full monitoring"""
    start_time = datetime.now()
    
    try:
        logger.info("Starting content generation",
                   requestId=requestId,
                   template=template_config.get("name"),
                   style=style_config.get("name"))
        
        # Use your enhanced graph
        result = await app_state.content_graph.generate_content(
            request_id=requestId,
            template_config=template_config,
            style_config=style_config
        )
        
        # Convert to API format
        status = GenerationStatus(
            requestId=requestId,
            status=result.status,
            progress=result.progress,
            current_step="Completed" if result.status == ProcessingStatus.COMPLETED else "Failed",
            content=result.content,
            metadata=result.metadata,
            errors=result.errors,
            warnings=result.warnings,
            metrics=result.metrics,
            created_at=result.started_at or start_time,
            updated_at=datetime.now(),
            completed_at=result.completed_at
        )
        
        app_state.generation_tasks[requestId] = status
        
        # Record metrics
        duration = (datetime.now() - start_time).total_seconds()
        GENERATION_DURATION.observe(duration)
        GENERATION_COUNT.labels(
            status=result.status,
            template=template_config.get("name", "unknown")
        ).inc()
        
        logger.info("Content generation completed",
                   requestId=requestId,
                   status=result.status,
                   duration=duration,
                   word_count=result.metrics.get("word_count", 0))
        
    except Exception as e:
        logger.error("Content generation failed",
                    requestId=requestId,
                    error=str(e),
                    exc_info=True)
        
        error_status = GenerationStatus(
            requestId=requestId,
            status="failed",
            progress=0.0,
            current_step="Failed",
            content="",
            metadata={},
            errors=[f"Generation failed: {str(e)}"],
            warnings=[],
            metrics={},
            created_at=start_time,
            updated_at=datetime.now()
        )
        
        app_state.generation_tasks[requestId] = error_status
        
        GENERATION_COUNT.labels(status="failed", template="unknown").inc()

# API Endpoints
@app.get("/", response_model=APIResponse)
async def root(request: Request):
    """API root endpoint with system information"""
    return APIResponse(
        success=True,
        data={
            "name": "Agentic Writer API",
            "version": "2.0.0",
            "status": "operational",
            "features": [
                "Enhanced LangGraph content generation",
                "Real-time progress tracking",
                "Comprehensive metrics",
                "Template and style management",
                "Production-ready monitoring"
            ],
            "endpoints": {
                "docs": "/docs",
                "health": "/health",
                "metrics": "/metrics",
                "templates": "/api/templates",
                "styles": "/api/style-profiles",
                "generate": "/api/generate"
            }
        },
        requestId=request.state.requestId
    )

@app.get("/health")
async def health_check(request: Request):
    """Comprehensive health check"""
    try:
        template_count = len(load_templates())
        profile_count = len(load_style_profiles())
        
        # Check if template/profile directories exist (more lenient check)
        template_dirs_exist = any(os.path.exists(path) for path in get_template_paths())
        profile_dirs_exist = any(os.path.exists(path) for path in get_style_profile_paths())
        
        health_data = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": {
                "content_graph": hasattr(app.state, 'content_graph'),
                "template_directories": template_dirs_exist,
                "style_profile_directories": profile_dirs_exist,
                "api_server": True
            },
            "metrics": {
                "templates_loaded": template_count,
                "profiles_loaded": profile_count,
                "active_generations": len(getattr(app.state, 'generation_tasks', {})),
                "template_directories_found": len(get_template_paths()),
                "style_directories_found": len(get_style_profile_paths())
            },
            "paths": {
                "template_paths": get_template_paths(),
                "style_profile_paths": get_style_profile_paths()
            },
            "system": {
                "python_version": "3.12+",
                "fastapi_version": "0.104+",
                "langgraph_enabled": LANGGRAPH_AVAILABLE,
                "mock_mode": not LANGGRAPH_AVAILABLE
            }
        }
        
        # For now, consider the service healthy if core services are running
        critical_services = [
            health_data["services"]["content_graph"],
            health_data["services"]["api_server"]
        ]
        
        all_healthy = all(critical_services)
        
        if not all_healthy:
            health_data["status"] = "unhealthy"
        elif template_count == 0 or profile_count == 0:
            health_data["status"] = "degraded"
        
        return JSONResponse(
            status_code=200 if all_healthy else 503,
            content=health_data
        )
        
    except Exception as e:
        logger.error("Health check failed", error=str(e), exc_info=True)
        
        error_health = {
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "services": {
                "content_graph": False,
                "template_directories": False,
                "style_profile_directories": False,
                "api_server": True
            }
        }
        
        return JSONResponse(
            status_code=503,
            content=error_health
        )

@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    return Response(generate_latest(custom_registry), media_type=CONTENT_TYPE_LATEST)

@app.get("/api/templates", response_model=APIResponse)
async def list_templates(request: Request):
    """List all available content templates"""
    try:
        templates = load_templates()
        
        return APIResponse(
            success=True,
            data={
                "items": [template.dict() for template in templates],
                "count": len(templates)
            },
            requestId=request.state.requestId
        )
        
    except Exception as e:
        logger.error("Failed to load templates", error=str(e))
        raise HTTPException(status_code=500, detail="Failed to load templates")

@app.get("/api/style-profiles", response_model=APIResponse)
async def list_style_profiles(
    request: Request,
    page: int = 1,
    limit: int = 100,
    search: str = "",
    category: str = ""
):
    """List style profiles with pagination and filtering"""
    try:
        profiles = load_style_profiles()
        
        # Apply filters
        if search:
            search_lower = search.lower()
            profiles = [
                p for p in profiles 
                if search_lower in p.name.lower() or 
                   search_lower in (p.description or "").lower()
            ]
        
        if category:
            profiles = [p for p in profiles if p.category.lower() == category.lower()]
        
        # Pagination
        total = len(profiles)
        total_pages = (total + limit - 1) // limit
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit
        paginated_profiles = profiles[start_idx:end_idx]
        
        pagination = PaginationMetadata(
            page=page,
            limit=limit,
            total=total,
            totalPages=total_pages,
            hasNext=page < total_pages,
            hasPrev=page > 1
        )
        
        return APIResponse(
            success=True,
            data={
                "items": [profile.dict() for profile in paginated_profiles],
                "pagination": pagination.dict()
            },
            requestId=request.state.requestId
        )
        
    except Exception as e:
        logger.error("Failed to load style profiles", error=str(e))
        raise HTTPException(status_code=500, detail="Failed to load style profiles")

@app.post("/api/generate", response_model=APIResponse)
async def generate_content_endpoint(
    request_data: GenerateRequest,
    background_tasks: BackgroundTasks,
    request: Request
):
    """Start content generation with enhanced monitoring"""
    requestId = request_data.requestId
    
    try:
        # Load and validate template
        templates = load_templates()
        template = next(
            (t for t in templates if t.id == request_data.template.replace('.yaml', '')),
            None
        )
        if not template:
            logger.error(f"Template not found: {request_data.template}")
            logger.error(f"Available templates: {[t.id for t in templates]}")
            raise HTTPException(status_code=404, detail=f"Template not found: {request_data.template}")
        
        # Load and validate style profile - IMPROVED LOGIC
        profiles = load_style_profiles()
        
        # Try multiple ways to find the profile
        profile = None
        search_terms = [
            request_data.style_profile,                    # exact match
            request_data.style_profile.replace('.yaml', ''), # without extension
            request_data.style_profile.replace('-', '_'),    # dash to underscore
            request_data.style_profile.replace('_', '-'),    # underscore to dash
        ]
        
        for search_term in search_terms:
            profile = next(
                (p for p in profiles if p.id == search_term),
                None
            )
            if profile:
                break
        
        if not profile:
            logger.error(f"Style profile not found: {request_data.style_profile}")
            logger.error(f"Available profiles: {[p.id for p in profiles]}")
            logger.error(f"Search terms tried: {search_terms}")
            raise HTTPException(
                status_code=404, 
                detail={
                    "success": False,
                    "data": None,
                    "error": {
                        "code": "HTTP_404",
                        "message": f"Style profile not found: {request_data.style_profile}",
                        "available_profiles": [p.id for p in profiles],
                        "timestamp": datetime.now().isoformat()
                    },
                    "timestamp": datetime.now().isoformat(),
                    "requestId": str(uuid.uuid4())
                }
            )
        
        logger.info(f"‚úÖ Found style profile: {profile.id} ({profile.name})")
        
        # Prepare configurations
        template_config = template.dict()
        template_config.update(request_data.dynamic_parameters)
        
        style_config = profile.dict()
        
        # Initialize generation status
        initial_status = GenerationStatus(
            requestId=requestId,
            status="pending",
            progress=0.0,
            current_step="Initializing...",
            content="",
            metadata={
                "template": template.name,
                "style_profile": profile.name,
                "started_at": datetime.now().isoformat()
            },
            errors=[],
            warnings=[],
            metrics={},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        app.state.generation_tasks[requestId] = initial_status
        
        # Start background generation
        background_tasks.add_task(
            generate_content_task,
            requestId,
            template_config,
            style_config,
            app.state
        )
        
        logger.info("Content generation initiated",
                   requestId=requestId,
                   template=template.name,
                   style_profile=profile.name)
        
        return APIResponse(
            success=True,
            data={
                "requestId": requestId,
                "status": "pending",
                "metadata": initial_status.metadata
            },
            requestId=request.state.requestId
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to start generation", 
                    error=str(e), 
                    requestId=requestId)
        raise HTTPException(status_code=500, detail="Failed to start content generation")

@app.get("/api/generate/status/{requestId}", response_model=APIResponse)
async def get_generation_result(requestId: str, request: Request):
    """Get generation status or final result"""
    if requestId not in app.state.generation_tasks:
        raise HTTPException(status_code=404, detail="Generation request not found")
    
    status = app.state.generation_tasks[requestId]
    print(f"üîç Generation endpoint - Content will be stored under: {requestId}")
    print(f"üîç Generation endpoint - Returning to frontend: {requestId}")
    print(f"üîç Generation endpoint - Middleware request ID: {request.state.requestId}")
    return APIResponse(
        success=True,
        data=status.dict(),
        requestId=request.state.requestId
    )

#@app.delete("/api/generate/{requestId}")
#async def cancel_generation(requestId: str, request: Request):
#    """Cancel an ongoing generation"""
#    if requestId not in app.state.generation_tasks:
#        raise HTTPException(status_code=404, detail="Generation request not found")
#    
#    status = app.state.generation_tasks[requestId]
#    if status.status in ["completed", "failed"]:
#        raise HTTPException(status_code=400, detail="Cannot cancel completed generation")
#    
#    # Update status to cancelled
#    status.status = "cancelled"
#    status.updated_at = datetime.now()
#    app.state.generation_tasks[requestId] = status
#    
#    logger.info("Generation cancelled", requestId=requestId)
#    
#    return APIResponse(
#        success=True,
#        data={"message": "Generation cancelled successfully"},
#        requestId=request.state.requestId
#    )

# Debug endpoints
@app.get("/debug/profiles")
async def debug_profiles(request: Request):
    """Debug endpoint to check style profile loading"""
    try:
        profiles = load_style_profiles()
        template_paths = get_template_paths()
        style_paths = get_style_profile_paths()
        
        return APIResponse(
            success=True,
            data={
                "current_working_directory": os.getcwd(),
                "template_paths_checked": [
                    {"path": path, "exists": os.path.exists(path)} 
                    for path in ["data/content_templates", "../data/content_templates", "frontend/content-templates", "../frontend/content-templates"]
                ],
                "style_paths_checked": [
                    {"path": path, "exists": os.path.exists(path)} 
                    for path in ["data/style_profiles", "../data/style_profiles", "frontend/style-profiles", "../frontend/style-profiles", "style_profiles", "style-profiles"]
                ],
                "template_paths_found": template_paths,
                "style_paths_found": style_paths,
                "profiles_loaded": [{"id": p.id, "name": p.name, "filename": p.filename} for p in profiles],
                "profile_count": len(profiles)
            },
            requestId=request.state.requestId
        )
    except Exception as e:
        logger.error("Debug profiles failed", error=str(e))
        return APIResponse(
            success=False,
            error={"message": str(e)},
            requestId=request.state.requestId
        )

@app.get("/debug/template-parsing")
async def debug_template_parsing(request: Request):
    """Debug how templates are being parsed"""
    try:
        debug_info = {
            "template_directories": get_template_paths(),
            "parsing_results": []
        }
        
        for template_dir in get_template_paths():
            if os.path.exists(template_dir):
                for filename in os.listdir(template_dir):
                    if filename.endswith('.yaml'):
                        file_path = os.path.join(template_dir, filename)
                        try:
                            template_data = load_yaml_file_safe(file_path)
                            parameters_data = template_data.get("parameters", {})
                            
                            # Test the parameter parsing
                            try:
                                processed_params = parse_template_parameters(parameters_data)
                                param_status = "success"
                                param_count = len(processed_params)
                                param_error = None
                            except Exception as e:
                                param_status = "failed"
                                param_count = 0
                                param_error = str(e)
                            
                            debug_info["parsing_results"].append({
                                "filename": filename,
                                "template_id": template_data.get('id', 'not_specified'),
                                "parameters_type": type(parameters_data).__name__,
                                "parameters_raw_count": len(parameters_data) if hasattr(parameters_data, '__len__') else 0,
                                "parameter_parsing_status": param_status,
                                "parameters_processed_count": param_count,
                                "parameter_error": param_error,
                                "first_few_keys": list(template_data.keys())[:5],
                                "parameters_sample": str(parameters_data)[:200] + "..." if len(str(parameters_data)) > 200 else str(parameters_data)
                            })
                            
                        except Exception as e:
                            debug_info["parsing_results"].append({
                                "filename": filename,
                                "status": "file_load_failed",
                                "error": str(e)
                            })
        
        return APIResponse(
            success=True,
            data=debug_info,
            requestId=request.state.requestId
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            error={"message": str(e)},
            requestId=request.state.requestId
        )

@app.get("/debug/file-structures")
async def debug_file_structures(request: Request):
    """Debug endpoint to show how files are being parsed"""
    try:
        debug_info = {
            "templates": [],
            "style_profiles": [],
            "parsing_results": {
                "templates_loaded": 0,
                "profiles_loaded": 0,
                "templates_failed": 0,
                "profiles_failed": 0
            }
        }
        
        # Debug templates
        for template_dir in get_template_paths():
            if os.path.exists(template_dir):
                for filename in os.listdir(template_dir):
                    if filename.endswith('.yaml'):
                        file_path = os.path.join(template_dir, filename)
                        try:
                            template_data = load_yaml_file_safe(file_path)
                            parameters_data = template_data.get("parameters", {})
                            
                            debug_info["templates"].append({
                                "filename": filename,
                                "id": template_data.get('id', 'not_specified'),
                                "name": template_data.get('name', 'not_specified'),
                                "parameters_type": type(parameters_data).__name__,
                                "parameters_count": len(parameters_data) if hasattr(parameters_data, '__len__') else 0,
                                "has_system_prompt": bool(template_data.get('system_prompt')),
                                "has_structure": bool(template_data.get('structure')),
                                "status": "parsed_successfully"
                            })
                            debug_info["parsing_results"]["templates_loaded"] += 1
                            
                        except Exception as e:
                            debug_info["templates"].append({
                                "filename": filename,
                                "status": "parse_failed",
                                "error": str(e)
                            })
                            debug_info["parsing_results"]["templates_failed"] += 1
        
        # Debug style profiles
        for profile_dir in get_style_profile_paths():
            if os.path.exists(profile_dir):
                for filename in os.listdir(profile_dir):
                    if filename.endswith('.yaml'):
                        file_path = os.path.join(profile_dir, filename)
                        try:
                            profile_data = load_yaml_file_safe(file_path)
                            
                            debug_info["style_profiles"].append({
                                "filename": filename,
                                "id": profile_data.get('id', 'not_specified'),
                                "name": profile_data.get('name', 'not_specified'),
                                "has_system_prompt": bool(profile_data.get('system_prompt')),
                                "has_length_limit": bool(profile_data.get('length_limit')),
                                "has_settings": bool(profile_data.get('settings')),
                                "status": "parsed_successfully"
                            })
                            debug_info["parsing_results"]["profiles_loaded"] += 1
                            
                        except Exception as e:
                            debug_info["style_profiles"].append({
                                "filename": filename,
                                "status": "parse_failed",
                                "error": str(e)
                            })
                            debug_info["parsing_results"]["profiles_failed"] += 1
        
        return APIResponse(
            success=True,
            data=debug_info,
            requestId=request.state.requestId
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            error={"message": str(e)},
            requestId=request.state.requestId
        )
# Add this endpoint to your server.py file, right after the existing endpoints

@app.get("/status/{requestId}")
async def get_generation_status(requestId: str, request: Request):
    """Get generation status - this is the endpoint your frontend is calling"""
    try:
        print(f"üîç Backend status check for request: {requestId}")
        
        # Check if generation task exists
        if requestId not in app.state.generation_tasks:
            print(f"‚ùå Request {requestId} not found in generation tasks")
            return JSONResponse(
                status_code=404,
                content={
                    "success": False,
                    "error": "Generation request not found",
                    "timestamp": datetime.now().isoformat(),
                    "requestId": requestId
                }
            )
        
        # Get the generation status
        status = app.state.generation_tasks[requestId]
        
        print(f"‚úÖ Found status for {requestId}: {status.status}")
        print(f"üìù Content length: {len(status.content)} characters")
        
        # Format response to match frontend expectations
        response_data = {
            "success": True,
            "data": {
                "requestId": requestId,
                "status": status.status,
                "progress": status.progress,
                "current_step": status.current_step,
                "content": status.content,
                "metadata": status.metadata,
                "errors": status.errors,
                "warnings": status.warnings,
                "metrics": status.metrics,
                "created_at": status.created_at.isoformat() if status.created_at else None,
                "updated_at": status.updated_at.isoformat() if status.updated_at else None,
                "completed_at": status.completed_at.isoformat() if status.completed_at else None
            },
            "error": None,
            "timestamp": datetime.now().isoformat(),
            "requestId": requestId
        }
        
        print(f"üîç Returning status: {status.status}, content_present: {bool(status.content)}")
        
        return JSONResponse(content=response_data)
        
    except Exception as e:
        print(f"‚ùå Error in status endpoint: {str(e)}")
        logger.error("Status check failed", requestId=requestId, error=str(e))
        
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": f"Status check failed: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "requestId": requestId
            }
        )


if __name__ == "__main__":
    uvicorn.run(
        "server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
        access_log=True
    )